#!/usr/bin/env python
from __future__ import print_function

import roslib
# roslib.load_manifest('exercise4')
import sys
import rospy
import cv2
import numpy as np
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
from std_msgs.msg import ColorRGBA
from cv_bridge import CvBridge, CvBridgeError

dictm = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)

# The object that we will pass to the markerDetect function
params = cv2.aruco.DetectorParameters_create()

print(params.adaptiveThreshConstant)
print(params.adaptiveThreshWinSizeMax)
print(params.adaptiveThreshWinSizeMin)
print(params.minCornerDistanceRate)
print(params.adaptiveThreshWinSizeStep)

# To see description of the parameters
# https://docs.opencv.org/3.3.1/d1/dcd/structcv_1_1aruco_1_1DetectorParameters.html

# You can set these parameters to get better marker detections
params.adaptiveThreshConstant = 25
adaptiveThreshWinSizeStep = 2


class The_Rectifier:
    def __init__(self):
        rospy.init_node('image_converter', anonymous=True)

        # An object we use for converting images between ROS format and OpenCV format
        self.bridge = CvBridge()

        # Subscribe to the image and/or depth topic
        self.image_sub = rospy.Subscriber(
            "/camera/rgb/image_color", Image, self.image_callback)

    def image_callback(self, data):
        # print('Iam here!')

        try:
            cv_image = self.bridge.imgmsg_to_cv2(data, "bgr8")
        except CvBridgeError as e:
            print(e)

        # Set the dimensions of the image
        self.dims = cv_image.shape

        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
        img = cv2.equalizeHist(gray)

        thresha = cv2.adaptiveThreshold(
            img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 23, 25)

        _, contoura, _ = cv2.findContours(
            thresha, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)

        candidates = self.find_candidates(contoura)

        for c in candidates:
            e1 = c[0]
            e2 = c[1]

            size = (e1[1][0] + e1[1][1]) / 2
            center = (e1[0][0], e1[0][1])

            x1 = int(center[0] - size / 2)
            x2 = int(center[0] + size / 2)

            x_min = x1 if x1 > 0 else 0
            x_max = x2 if x2 < cv_image.shape[0] else cv_image.shape[0]

            y1 = int(center[1] - size / 2)
            y2 = int(center[1] + size / 2)

            y_min = y1 if y1 > 0 else 0
            y_max = y2 if y2 < cv_image.shape[1] else cv_image.shape[1]
            print(x_min)
            print(x_max)
            print(y_min)
            print(y_max)

        ###########################################
        # THIS IS THE CODE THAT IT IS RELEVANT TO YOU
        # IT SHOULD BE INCLUDED IN YOUR OWN FUNCTION FOR RING DETECTION
        ###########################################

        if len(candidates) == 1:
            image_size = (351*2, 248*2, 3)

            img_out = np.zeros(image_size, np.uint8)
            width = img_out.shape[1]
            height = img_out.shape[0]
            out_pts = np.array([[width/2,                    30],
                                [0,                        height/2],
                                [width/2,                    height-30],
                                [width-0,                   height/2]])

            src_points = np.zeros((4, 2), dtype=np.int32)

            src_points[0] = [int(center[0]), y_min]
            src_points[1] = [x_min, int(center[1])]
            src_points[2] = [int(center[0]), y_max]
            src_points[3] = [x_max,int(center[1])]

            cv2.circle(cv_image,tuple(src_points[0]),1,(0,0,255),-1)
            cv2.circle(cv_image,tuple(src_points[1]),1,(0,0,255),-1)
            cv2.circle(cv_image,tuple(src_points[2]),1,(0,0,255),-1)
            cv2.circle(cv_image,tuple(src_points[3]),1,(0,0,255),-1)

            print(src_points)
            print(out_pts)

            h, status = cv2.findHomography(src_points, out_pts)
            img_out = cv2.warpPerspective(
                cv_image, h, (img_out.shape[1], img_out.shape[0]))

            cv2.imshow('Warped image', img_out)
            cv2.waitKey(1)

        elif len(candidates) == 0:
            print('No contours detected')
        else:
            print('Some contours detected, not sure if it is a ring', len(candidates))
            for elps in candidates:
                e1 = elps[0]
                e2 = elps[0]
                cv2.ellipse(cv_image, e1, (0, 255, 0), 3)
                cv2.ellipse(cv_image, e2, (0, 255, 0), 3)
            # cv2.imshow('Image',cv_image)
            # cv2.waitKey(1)

    def find_candidates(self, contours):
        elps = [cv2.fitEllipse(cnt) for cnt in contours if cnt.shape[0] >= 20]
        candidates = []
        for n in range(len(elps)):
            for m in range(n + 1, len(elps)):
                candidates += self.isCircle2(elps[n], elps[m])
        return candidates

    def isCircle2(self, e1, e2):
        (x1, y1), (minoraxis1, majoraxis1), angle1 = e1
        (x2, y2), (minoraxis2, majoraxis2), angle2 = e2
        if (0.22 < abs(majoraxis1/majoraxis2-1) < 0.32 and
            0.22 < abs(minoraxis1/minoraxis2-1) < 0.32 and
            abs(minoraxis1/majoraxis2-1) < 0.65 and
            abs(majoraxis1/minoraxis2-1) < 0.35 and
            20 < minoraxis1 < 85 and
                np.sqrt(((x1 - x2) ** 2 + (y1 - y2) ** 2)) < 5):
            print(abs(majoraxis1/majoraxis2-1))
            print(abs(minoraxis1/minoraxis2-1))
            print(abs(minoraxis1/majoraxis2-1))
            print(abs(majoraxis1/minoraxis2-1))
            print(minoraxis1)
            print()
            return [(e1, e2)]
        return []

    def cropImage(self, cv_image, top, bottom):
        cv_image[0:top] = 0
        cv_image[bottom:] = 0


def main(args):

    ring_rectifier = The_Rectifier()

    try:
        rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")

    cv2.destroyAllWindows()


if __name__ == '__main__':
    main(sys.argv)
